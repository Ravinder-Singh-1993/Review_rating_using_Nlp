{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c616ad24",
   "metadata": {},
   "source": [
    "## Web Scraping for Rating Review Prediction Project \n",
    "### By: Ravinder Siingh\n",
    "\n",
    "### Batch : Internship 28\n",
    "\n",
    "## Web Scraping details:\n",
    "### Data for this project is Scrap from Amazon & Flipkart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ac8edc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web Scraping for Ratting Project Part - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3bcd3b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required library\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2c03325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_template(search_term,page_no=1):\n",
    "    \"\"\"Generate a URL for search Term with page number\"\"\"\n",
    "    search_term = search_term.replace(' ','+')\n",
    "    template = f'https://www.amazon.in/s?k={search_term}&page={page_no}&qid=1623864210&ref=sr_pg_{page_no}'\n",
    "    \n",
    "    return template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "110e74af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url():#the function that generated URL with the search tearm.\n",
    "    iteams = ['laptops', 'Phones', 'Headphones', 'smart watches', 'Professional Cameras', 'Printers', 'scanners', 'keyboard', 'monitors', 'Home theater', 'router']\n",
    "    URL = []     \n",
    "    for i in iteams:\n",
    "        for j in range(1,15):\n",
    "            URL.append(get_template(i,j))\n",
    "    return URL        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3f2d0096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_review_url(): #the function that scraps the URL of the front page of the reviews and rattings with the search tearm.\n",
    "    \n",
    "    hreff = []\n",
    "    driver = webdriver.Chrome(r\"D:\\chromedriver.exe\") \n",
    "    driver.maximize_window()\n",
    "\n",
    "    URL = get_url()\n",
    "    for k in URL:\n",
    "        driver.get(k) #Opening with the URL template\n",
    "\n",
    "        for l in driver.find_elements_by_xpath(\"//a[@class = 'a-link-normal']\"):\n",
    "            hreff.append(l.get_attribute(\"href\"))   \n",
    "    return hreff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d1af2a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "875"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "href = get_review_url()\n",
    "len(href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "efd8fbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_review(): #the function that scraps the URL of all the reviews and rattings\n",
    "    \n",
    "    driver = webdriver.Chrome(r\"D:\\chromedriver.exe\") #Calling the Web Driver\n",
    "    driver.maximize_window()\n",
    "    rattings = []\n",
    "    review = []\n",
    "\n",
    "    for i in href:\n",
    "        driver.get(i) #Opening with the URL template\n",
    "        \n",
    "        try: #scraping the URL of the full review pages\n",
    "            link = driver.find_element_by_xpath(\"//a[@data-hook='see-all-reviews-link-foot']\")\n",
    "            link = link.get_attribute(\"href\")\n",
    "            link= link.split('ref=cm')[0]\n",
    "        except:\n",
    "            pass     \n",
    "        \n",
    "        for i in range(1,5): #Scraping Reviews and Rattings\n",
    "            l1= f'ref=cm_cr_getr_d_paging_btm_next_{i}?ie=UTF8&reviewerType=all_reviews&pageNumber={i}'\n",
    "            l = link+ l1 \n",
    "            \n",
    "            \n",
    "            driver.get(l)\n",
    "            \n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            results = soup.find_all('div',{'class' : 'a-section celwidget'})\n",
    "        \n",
    "            for item in results:\n",
    "                    try:\n",
    "                        rev = item.find('span', {'data-hook': \"review-body\"})\n",
    "                        atag = item.find(['a'], class_ = \"a-link-normal\")\n",
    "                        if rev.span.text.replace('\\n','').strip() and atag['title'][0]:\n",
    "                            review.append(rev.span.text.replace('\\n','').strip())\n",
    "                            rattings.append(atag['title'][0])\n",
    "                        else:\n",
    "                            break\n",
    "                    except:\n",
    "                        break\n",
    "       \n",
    "    driver.close()\n",
    "    \n",
    "    rat = pd.DataFrame({'Rattings':rattings, \"Review\": review})\n",
    "    \n",
    "    #saving the dataframe in csv\n",
    "    rat.to_csv(\"Rattings1.csv\",index=False) #Creating CSV\n",
    "    \n",
    "    return rat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9c37a746",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rattings</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Colour is very unique. Performance is excellen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>impressive laptop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Product is superb goodI just love it  there is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>You will never feel bad about any penny spend ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Compare and buy. Good one but keyboard not wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24647</th>\n",
       "      <td>5</td>\n",
       "      <td>I have been using Google wifi first gen for al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24648</th>\n",
       "      <td>4</td>\n",
       "      <td>Alright.. here is my view after using for 3 we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24649</th>\n",
       "      <td>5</td>\n",
       "      <td>Netgear Orbi RBK50 model is among top notch me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24650</th>\n",
       "      <td>5</td>\n",
       "      <td>It's been over a month now that I've been usin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24651</th>\n",
       "      <td>4</td>\n",
       "      <td>Initially I bought RBR40 assuming that it woul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24652 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rattings                                             Review\n",
       "0            4  Colour is very unique. Performance is excellen...\n",
       "1            4                                  impressive laptop\n",
       "2            4  Product is superb goodI just love it  there is...\n",
       "3            5  You will never feel bad about any penny spend ...\n",
       "4            3  Compare and buy. Good one but keyboard not wor...\n",
       "...        ...                                                ...\n",
       "24647        5  I have been using Google wifi first gen for al...\n",
       "24648        4  Alright.. here is my view after using for 3 we...\n",
       "24649        5  Netgear Orbi RBK50 model is among top notch me...\n",
       "24650        5  It's been over a month now that I've been usin...\n",
       "24651        4  Initially I bought RBR40 assuming that it woul...\n",
       "\n",
       "[24652 rows x 2 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rat = get_review()\n",
    "Rat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "270de988",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rat.to_csv(\"Rattings_scraped.csv\",index=False)# saving Data frame as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4df3e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
